<div align="center">
  <h1>Industr_IA: Plataforma de Mantenimiento Predictivo para la Industria 4.0</h1>
</div>

<p>
Este proyecto, <strong>Industr_IA</strong>, es una plataforma integral de mantenimiento predictivo diseÃ±ada para anticipar fallos en mÃ¡quinas industriales hasta con tres dÃ­as de antelaciÃ³n. Utilizando un modelo de Deep Learning (LSTM), la plataforma analiza datos de sensores en tiempo real para minimizar las paradas de producciÃ³n no planificadas y optimizar las operaciones de mantenimiento.
</p>

<p align="center">
  <img src="xd.gif" alt="DemostraciÃ³n de la Plataforma" width="80%">
</p>

---

## ğŸš€ TecnologÃ­as Utilizadas
*   **Proveedor Cloud:** AWS (Amazon Web Services)
*   **Infraestructura como CÃ³digo:** Terraform
*   **Modelo de Machine Learning:** Python, TensorFlow (Keras), Scikit-learn
*   **Ingesta y Procesamiento de Datos:** AWS IoT Core, AWS Lambda
*   **Almacenamiento de Datos:** Amazon Timestream, Amazon S3
*   **Despliegue del Modelo:** Amazon SageMaker
*   **MonitorizaciÃ³n y Alertas:** Amazon CloudWatch, Amazon SNS
*   **VisualizaciÃ³n:** Grafana

---

## ğŸ—ï¸ Arquitectura de Infraestructura en AWS

La soluciÃ³n estÃ¡ desplegada en una **arquitectura serverless y orientada a eventos en AWS**, lo que garantiza escalabilidad, flexibilidad y eficiencia en costos.

<p align="center">
  <img src="Img/Infraestructura.png" alt="Arquitectura de Infraestructura" width="70%">
</p>

### Flujo de Datos
1.  **Planta:** Los sensores en la mÃ¡quina envasadora envÃ­an datos a travÃ©s de un Access Point industrial a un topic MQTT (`topic/maquinas/+`).
2.  **Ingesta:** Una regla de **AWS IoT Core** se suscribe al topic MQTT. Al recibir un mensaje, desencadena mÃºltiples acciones.
3.  **Almacenamiento de Datos Crudos:** El payload JSON crudo se almacena en un bucket de **Amazon S3** para respaldo y anÃ¡lisis futuros.
4.  **Almacenamiento en Series de Tiempo:** Los datos se escriben en una base de datos de **Amazon Timestream**, optimizada para series temporales y que sirve como fuente para los dashboards de Grafana.
5.  **Procesamiento en Tiempo Real:** La regla de IoT invoca una funciÃ³n **AWS Lambda**, pasando los datos del sensor como payload del evento.
6.  **PredicciÃ³n:** La funciÃ³n Lambda preprocesa los datos usando un `StandardScaler` guardado e invoca un **Endpoint de Amazon SageMaker** para obtener una predicciÃ³n de fallo.
7.  **Alojamiento del Modelo:** El modelo LSTM estÃ¡ alojado en un Endpoint de SageMaker, que escala automÃ¡ticamente para manejar las solicitudes de predicciÃ³n.
8.  **Alertas:** Si el modelo predice una alta probabilidad de fallo (`pre_falla`), la funciÃ³n Lambda publica un mensaje en un topic de **Amazon SNS**, que envÃ­a una notificaciÃ³n por correo electrÃ³nico al equipo de mantenimiento.
9.  **Manejo de Errores:** Si la regla de IoT Core no puede procesar un mensaje, este se envÃ­a a una cola de **Amazon SQS** como Dead-Letter Queue (DLQ) para su inspecciÃ³n posterior.
10. **VisualizaciÃ³n:** **Grafana** se conecta directamente a Amazon Timestream para mostrar dashboards en tiempo real del estado de la maquinaria y las predicciones del modelo.

---

## ğŸ¤– Arquitectura del Modelo LSTM

El nÃºcleo de la plataforma es una red neuronal recurrente **Long Short-Term Memory (LSTM)** apilada. Esta arquitectura es ideal para analizar secuencias de datos temporales de mÃºltiples sensores, permitiendo aprender patrones complejos que preceden a un fallo. El modelo incluye capas de regularizaciÃ³n como Dropout y Batch Normalization para evitar el sobreajuste y mejorar la generalizaciÃ³n.

<p align="center">
  <img src="Img/ArquitecturaLTSM.png" alt="Arquitectura del Modelo LSTM" width="200">
</p>

---

## ğŸ“‚ Estructura del Proyecto

```
AIEngennier-Industr_IA/
â”œâ”€â”€ DataSet/
â”‚   â””â”€â”€ ds_envasadoras.csv         # Dataset de entrenamiento y validaciÃ³n
â”œâ”€â”€ Img/
â”‚   â””â”€â”€ *.png                     # ImÃ¡genes y diagramas para la documentaciÃ³n
â”œâ”€â”€ terraform_project_AWS/
â”‚   â”œâ”€â”€ lambda_function/
â”‚   â”‚   â”œâ”€â”€ lambda_function.py    # CÃ³digo Python para la Lambda de inferencia
â”‚   â”‚   â””â”€â”€ standard_scaler.save  # Scaler para el preprocesamiento de datos
â”‚   â”œâ”€â”€ sagemaker_model/
â”‚   â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”‚   â””â”€â”€ inference.py      # Script de Python para servir el modelo en SageMaker
â”‚   â”‚   â””â”€â”€ model.tar.gz          # Artefactos del modelo comprimidos
â”‚   â”œâ”€â”€ *.tf                      # Archivos de Terraform para la infraestructura de AWS
â”‚   â””â”€â”€ variables.tf              # Variables de entrada para Terraform
â”œâ”€â”€ best_lstm_model.keras         # Modelo Keras entrenado
â”œâ”€â”€ Industr_IA_vF.ipynb           # Jupyter Notebook para el entrenamiento (almacenado en Git LFS)
â””â”€â”€ README.md                     # Este archivo
```

---

## ğŸ› ï¸ Despliegue

Toda la infraestructura de AWS se gestiona con Terraform.

### Prerrequisitos
*   Tener [Terraform CLI](https://learn.hashicorp.com/tutorials/terraform/install-cli) instalado.
*   Una cuenta de AWS con credenciales configuradas para Terraform.
*   El artefacto `model.tar.gz` subido a un bucket de S3.

### Pasos
1.  **Navega al directorio de Terraform:**
    ```bash
    cd terraform_project_AWS
    ```
2.  **Inicializa Terraform:**
    Este comando descarga los plugins necesarios del proveedor de AWS.
    ```bash
    terraform init
    ```
3.  **Configura las Variables:**
    Crea un archivo `terraform.tfvars` o exporta variables de entorno para establecer los valores requeridos de `variables.tf`, tales como:
    *   `aws_region`: La regiÃ³n de AWS donde se desplegarÃ¡ (ej. "us-east-1").
    *   `alert_email`: La direcciÃ³n de correo para recibir notificaciones de SNS.
    *   `sagemaker_model_s3_bucket`: El nombre del bucket de S3 que contiene el artefacto del modelo.
    *   `sagemaker_model_s3_key`: La ruta (key) al archivo `model.tar.gz` en el bucket.

4.  **Planifica el despliegue:**
    Este comando muestra los recursos que se crearÃ¡n.
    ```bash
    terraform plan
    ```
5.  **Aplica la configuraciÃ³n:**
    Este comando aprovisiona todos los recursos de AWS. Escribe `yes` cuando se te solicite.
    ```bash
    terraform apply
    ```

---

## ğŸ“Š Dashboards de MonitorizaciÃ³n en Tiempo Real
Se desarrollaron dashboards en Grafana para visualizar el estado de la maquinaria y las predicciones del modelo en tiempo real, proporcionando inteligencia accionable al personal de planta.

### Estado Normal
El dashboard muestra una probabilidad de fallo baja y los valores de los sensores dentro de los rangos operativos normales.
<p align="center">
  <img src="Img/Monitorizacion_OK.png" alt="Dashboard en Estado Normal" width="70%">
</p>

### PredicciÃ³n de Falla
El sistema detecta una anomalÃ­a y la probabilidad de fallo aumenta significativamente, alertando sobre un posible problema inminente.
<p align="center">
  <img src="Img/Monitorizacion_Falla.png" alt="Dashboard con PredicciÃ³n de Falla" width="70%">
</p>

### MÃ¡quina Detenida
Cuando la mÃ¡quina estÃ¡ parada, los sensores no reportan datos, lo cual se refleja inmediatamente en el dashboard.
<p align="center">
  <img src="Img/Monitorizacion_Parada.png" alt="Dashboard con MÃ¡quina Detenida" width="70%">
</p>

---

## ğŸ”” Sistema de Alertas Predictivas
Cuando el modelo predice una alta probabilidad de fallo, el sistema envÃ­a automÃ¡ticamente una **alerta por correo electrÃ³nico** al equipo de mantenimiento. La notificaciÃ³n incluye los valores de los sensores al momento de la alarma para facilitar un diagnÃ³stico rÃ¡pido.

<p align="center">
  <img src="Img/AlertaFallaPredictiva.png" alt="NotificaciÃ³n de Alerta de Falla Predictiva" width="70%">
</p>

---

## ğŸ¯ Resultados del Modelo

El modelo predictivo fue evaluado rigurosamente, demostrando una alta efectividad para la detecciÃ³n de fallos:

*   **PrecisiÃ³n Global (Accuracy):** 96%
*   **Sensibilidad (Recall):** 99%

Estos resultados confirman la viabilidad tÃ©cnica de la soluciÃ³n y su capacidad para minimizar las paradas inesperadas.
